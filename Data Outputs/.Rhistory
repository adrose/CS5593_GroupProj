"Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire",
"New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota",
"Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina",
"South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington",
"West Virginia", "Wisconsin", "Wyoming"),
options = list(maxItems = 5),
selected = "Alabama"),
dateRangeInput("timeline_date", "Choose date range:",
start = "2020-04-13",
end = "2020-09-19",
min = "2020-04-13",
max = "2020-09-19",
format = "yy/mm/dd",
separator = " - "))
),
fluidRow(
box(title = "Twitter words frequency over time", solidHeader = TRUE,
collapsible = TRUE, status = "success",
plotOutput("wordmap", height = 500)),
box(title = "Inputs", solidHeader = TRUE,
collapsible = TRUE, status = "success", height = 560,
helpText("This plot represents the most commonly used words in",
"COVID-19 related tweets averaged over time.",
"You may plot up to 411 words at the same time. They are drawn",
"in no particular order from the dataset.",
"In addition, you can also modify the timeline between two",
"particular dates from 04/13/2020 to 09/19/2020 to investigate",
"changes over time.",
"Lastly, you can remove COVID-19 references from the wordmap",
"(e.g. covid, covid19, coronavirus) from the wordmap."),
numericInput("numb_words", "Number of words to populate map",
min = 10, max = 411, value = 10),
dateRangeInput("wordmap_date", "Choose date range:",
start = "2020-04-13",
end = "2020-09-19",
min = "2020-04-13",
max = "2020-09-19",
format = "yy/mm/dd",
separator = " - "),
checkboxInput("remove_covid", "Remove COVID-19 references", value = FALSE))
)
)
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
52:463
463 - 52
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
runApp('F:/2. PhD/2. Github/CS5593_GroupProj/Dashboard')
### Defining working directory ----
script_location <- getwd()
root_folder <- dirname(script_location)
data_folder <- paste0(root_folder, '/Data Outputs')
svr_location <- paste0(root_folder, '/Algorithms/SVR/')
rf_location <- paste0(script_location, "/RandomForest")
knn_location <- script_location
### Sourcing SVR auxiliary R files ----
setwd(svr_location)
source('svr_functions.R')
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
# Libraries for RF
library(foreach)
library(doParallel)
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
# Extracting Y (includes all states + districts)
# Y_all = data[, 1:52]
# But for now, let's just test one single Y
Y = data[, 2]
# Generally, we would use all predictors:
# X = data[, 53:ncol(data)]
# But for now, let's test just a couple
X = data[, 54:ncol(data)]
# Scaling the data
X = scale(X)
Y = scale(Y)
## Defining the cross validation parameters
# start_size = 40
# K = 10
start_size = 100
K = 30
model = "SVR"
### Defining hyperparameter grid
## SVR
# degree of polynomials (No more than 2)
p1 = seq(from = 1, to = 2, by = 1)
# type of kernel
ke = c("polynomial", "linear")
# Cost
C = seq(from = 1, to = 5, by = 1)
# e (No more than 0.5)
e = seq(from = 0.1, to = 0.5, by = 0.1)
# Creating the grid
hyperparameters <- expand.grid(poly_deg = p1, ke = ke,
C = C, e = e)
### Running the function
wew <- roll_cross_validation(X, Y, start_size, K, model, hyperparameters)
Y = as.data.frame(data[, 2])
colnames(Y) <- colnames(data[2])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 200, to = 250, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
Y = as.data.frame(data[, 2])
colnames(Y) <- colnames(data[2])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 200, to = 250, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
View(reg_tree_imp)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Defining working directory ----
script_location <- getwd()
root_folder <- dirname(script_location)
data_folder <- paste0(root_folder, '/Data Outputs')
svr_location <- paste0(root_folder, '/Algorithms/SVR/')
rf_location <- paste0(script_location, "/RandomForest")
knn_location <- script_location
### Sourcing SVR auxiliary R files ----
setwd(svr_location)
source('svr_functions.R')
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
# Libraries for RF
library(foreach)
library(doParallel)
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
Y = as.data.frame(data[, 2])
colnames(Y) <- colnames(data[2])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[2])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
View(Y)
# Extracting parameters
n_trees <- hyperparameters[i, 1]
feature_frac <- hyperparameters[i, 2]
min_node <- hyperparameters[i, 3]
# Defining the formula from X and Y.
form.val <- as.formula(paste(colnames(Y), "~", paste(colnames(X), collapse = "+")))
# Defining a list that will then be used to calculate average RMSE
RMSE_vector <- c()
indx = 1
# Resetting parameters
start_size_svr = start_size
i = 1
start_size = 40
K = 10
# Defining parallels
registerDoParallel(5)
# Extracting parameters
n_trees <- hyperparameters[i, 1]
feature_frac <- hyperparameters[i, 2]
min_node <- hyperparameters[i, 3]
# Defining the formula from X and Y.
form.val <- as.formula(paste(colnames(Y), "~", paste(colnames(X), collapse = "+")))
# Defining a list that will then be used to calculate average RMSE
RMSE_vector <- c()
indx = 1
# Resetting parameters
start_size_svr = start_size
while(start_size_svr < nrow(X)){
## Splitting data on a rolling basis
# Defining the train validation
train_X <- X[1:start_size_svr, ]
train_Y <- Y[1:start_size_svr, ]
train_data <- cbind(train_Y, train_X)
# Increasing the counter
start_size_svr <- start_size_svr + K
# Defining the test validation
test_X <- X[(dim(train_X)[1] + 1):start_size_svr, ]
test_Y <- Y[(length(train_Y) + 1):start_size_svr, ]
test_data <- cbind(test_Y, test_X)
########################################################
########################################################
# Training
mod.1 <- run_rf(formula = form.val,
n_trees = n_trees,
feature_frac = feature_frac,
data = train_data,
min_node = min_node)
# Testing
mod.1.pred <- pred_new_rd(rf_fit = mod.1,
data = test_data)
# Calculating RMSE
RMSE_val <- RMSE(mod.1.pred, test_Y)
# Adding to list, plus increasing counter
RMSE_vector[indx] <- RMSE_val
indx = indx + 1
}
# extract features
features <- all.vars(formula)[-1]
formula = form.val
# extract features
features <- all.vars(formula)[-1]
# extract target
target <- all.vars(formula)[1]
# bag the data
# - randomly sample the data with replacement (duplicate are possible)
index <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
train <- data[index,]
# randomly sample features
# - only fit the regression tree with feature_frac * 100 % of the features
features_sample <- sample(features,
size = ceiling(length(features) * feature_frac),
replace = FALSE)
# create new formula
formula_new <- as.formula(paste0(target, " ~ -1 + ", paste0(features_sample,
collapse =  " + ")))
tree <- reg_tree_imp(formula = formula_new, data = train, minsize = min_node)
## Now return a column of the predicted values; one per observation
fit.vals <- cbind(index, tree$fit)[order(index),]
fit.vals <- as.data.frame(unique(fit.vals))
## Now merge these with an na list
index2 <- 1:dim(data)[1]
target <- as.data.frame(index2)
fit.vals <- merge(target, fit.vals, by.x = "index2", by.y = "index", all=T)[,2]
imp.vals <- tree$importance
target <- as.data.frame(features)
imp.vals <- merge(target, imp.vals, by.x="features", by.y="FEATURES", all=T)
out.list <- list(fit = fit.vals, imp = imp.vals, splits = tree$tree)
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
## Splitting data on a rolling basis
# Defining the train validation
train_X <- X[1:start_size_svr, ]
train_Y <- Y[1:start_size_svr, ]
View(train_X)
train_Y <- as.data.frame(Y[1:start_size_svr, ])
View(train_Y)
colnames(Y)
colnames(train_Y) <- colnames(Y)
View(train_Y)
### Sourcing SVR auxiliary R files ----
setwd(svr_location)
source('svr_functions.R')
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
# Libraries for RF
library(foreach)
library(doParallel)
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
# Defining parallels
registerDoParallel(5)
# Extracting parameters
n_trees <- hyperparameters[i, 1]
feature_frac <- hyperparameters[i, 2]
min_node <- hyperparameters[i, 3]
# Defining a list that will then be used to calculate average RMSE
RMSE_vector <- c()
indx = 1
# Resetting parameters
start_size_svr = start_size
# Defining the formula from X and Y.
formula <- as.formula(paste(colnames(Y), "~", paste(colnames(X), collapse = "+")))
## Splitting data on a rolling basis
# Defining the train validation
train_X <- X[1:start_size_svr, ]
train_Y <- as.data.frame(Y[1:start_size_svr, ])
colnames(train_Y) <- colnames(Y)
train_data <- cbind(train_Y, train_X)
View(train_data)
View(train_X)
View(train_Y)
View(train_data)
# Increasing the counter
start_size_svr <- start_size_svr + K
# Defining the test validation
test_X <- X[(dim(train_X)[1] + 1):start_size_svr, ]
test_Y <- as.data.frame(Y[(length(train_Y) + 1):start_size_svr, ])
colnames(test_Y) <- colnames(Y)
test_data <- cbind(test_Y, test_X)
# Defining the test validation
test_X <- X[(dim(train_X)[1] + 1):start_size_svr, ]
test_Y <- as.data.frame(Y[(length(train_Y) + 1):start_size_svr, ])
K = 10
start_size = 40
# Defining parallels
registerDoParallel(5)
# Extracting parameters
n_trees <- hyperparameters[i, 1]
feature_frac <- hyperparameters[i, 2]
min_node <- hyperparameters[i, 3]
# Defining a list that will then be used to calculate average RMSE
RMSE_vector <- c()
indx = 1
# Resetting parameters
start_size_svr = start_size
# Defining the formula from X and Y.
formula <- as.formula(paste(colnames(Y), "~", paste(colnames(X), collapse = "+")))
## Splitting data on a rolling basis
# Defining the train validation
train_X <- X[1:start_size_svr, ]
train_Y <- as.data.frame(Y[1:start_size_svr, ])
colnames(train_Y) <- colnames(Y)
train_data <- cbind(train_Y, train_X)
# Increasing the counter
start_size_svr <- start_size_svr + K
# Defining the test validation
test_X <- X[(dim(train_X)[1] + 1):start_size_svr, ]
test_Y <- as.data.frame(Y[(length(train_Y) + 1):start_size_svr, ])
colnames(test_Y) <- colnames(Y)
(length(train_Y) + 1):start_size_svr
start_size_svr
(length(train_Y) + 1)
(nrow(train_Y) + 1):start_size_svr
test_Y <- as.data.frame(Y[(nrow(train_Y) + 1):start_size_svr, ])
colnames(test_Y) <- colnames(Y)
test_data <- cbind(test_Y, test_X)
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing SVR auxiliary R files ----
setwd(svr_location)
source('svr_functions.R')
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
# Libraries for RF
library(foreach)
library(doParallel)
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)
### Sourcing SVR auxiliary R files ----
setwd(svr_location)
source('svr_functions.R')
### Sourcing Cross validation file ----
setwd(script_location)
source('rolling_cross_validation.R')
### Sourcing RF R files ----
setwd(rf_location)
source('randomForestFunctions.R')
# Libraries for RF
library(foreach)
library(doParallel)
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
Y = as.data.frame(data[, 3])
colnames(Y) <- colnames(data[3])
X = data[, 54:ncol(data)]
n_trees <- seq(from = 10, to = 20, by = 5)
feature_frac <- seq(from = 0.5, to = 0.75, by = 0.05)
min_node <- seq(from = 1, to = 3, by = 1)
hyperparameters <- expand.grid(n_trees = n_trees, feature_frac = feature_frac,
min_node = min_node)
registerDoParallel(5)
wew <- roll_cross_validation(X, Y, start_size = 40, K = 10, model = "RF", hyperparameters)

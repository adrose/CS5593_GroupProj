### Defining working directory ----
script_location <- getwd()
root_folder <- dirname(dirname(script_location))
data_folder <- paste0(root_folder, '/Data Outputs')
### Libraries used ----
library(kernlab) # For the ipop() function, to solve a quadratic programming problem.
library(fpp2) # Nice ggplot2 wrappers for time series data
### Sourcing auxiliary R files ----
setwd(script_location)
source('svr_functions.R')
### Loading data ----
setwd(data_folder)
data <- read.csv("combined_processed_data.csv")
# Extracting Y (includes all states + districts)
# Y_all = data[, 1:52]
# But for now, let's just test one single Y
Y = data[, 2]
# Generally, we would use all predictors:
# X = data[, 53:ncol(data)]
# But for now, let's test just a couple
X = data[, 53:ncol(data)]
# Defining the model using the functions from svr_functions.R and the
# library(kernlab) ipop() function to solve the
# SVM QP e-loss function formulation
svr_model <- function(X, Y, n, ke, p1, C, e, epsilon){
####################################################################
#
# This function takes the X matrix, the Y matrix, as well as
# the C, e, and epsilon hyperparameters
#
####################################################################
# Step 1
# Then, running the hess_mat function from svr_functions.R
# Here, we're implementing a linear kernel
H <- hess_mat(X, n, ke, p1)
# Step 2: Calculating the optimization parameters for the qp algorithm
# This is done using optim_params from svr_functions.R
qp_params <- optim_params(H, e, n, Y, C)
# Step 3: Running the qp algorithm using ipop() from library(kernlab)
outputs <- ipop(as.matrix(qp_params[[1]]), as.matrix(qp_params[[2]]), as.matrix(qp_params[[6]]),
as.matrix(qp_params[[7]]), as.matrix(qp_params[[3]]), as.matrix(qp_params[[4]]),
0)
# Step 4: Running the svr_vals from svr_functions.R
# to get the Beta and biases.
results <- svr_vals(outputs, n, Y, epsilon, H)
return(results)
}
# First, scaling the data
X = scale(X)
Y = scale(Y)
# Then, defining the number of data objects and all other hyperparameters
n = dim(X)[1]
p1 = 2
ke = "polynomial"
C = 1
e = 0.05
epsilon = 0.5
# Finally, running the model
results <- svr_model(X, Y, n, ke, p1, C, e, epsilon)
# Extracting the estimated beta, and the two bias implementations
beta <- as.matrix(results[[1]])
bias1 <- results[[2]]
bias2 <- results[[3]]
bias3 <- results[[4]]
# Finding the fitted values
# We have to define H (just like we do in svr_model)
H <- hess_mat(X, n, ke, p1)
# Calculating the fitted values
svr_fit2 <- H %*% beta + bias2
svr_fit3 <- H %*% beta + bias3
svr_fit1 <- H %*% beta
# Checking the fits!
autoplot(ts(Y)) +
autolayer(ts(svr_fit2))
